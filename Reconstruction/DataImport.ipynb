{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "%run 'multilabel.ipynb'\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    \n",
    "    def __init__(self, datapath, dataset_type = 'micro_2D', val_size=0.3, batch_size=16, test=False):\n",
    "        \n",
    "        self.datapath = datapath\n",
    "        self.val_size = val_size\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_type = dataset_type\n",
    "        \n",
    "        # boolean for test mode\n",
    "        self.test = test\n",
    "        \n",
    "        # params based on dataset type\n",
    "        if self.dataset_type == 'nano_2D':\n",
    "            self.height = 56\n",
    "            self.width = 56\n",
    "        elif self.dataset_type == 'micro_2D':\n",
    "            self.height = 128\n",
    "            self.width = 128\n",
    "        else:\n",
    "            raise NotImplementedError(\"Please set dataset_type as raw, micro, or nano.\")\n",
    "        \n",
    "        \n",
    "        # for tracking errors\n",
    "        self.bad_images = []\n",
    "        \n",
    "        # training and validation\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = self.split_training_into_validation()\n",
    "    \n",
    "        # params of data based on training data\n",
    "        self.num_samples = self.y_train.shape[0]\n",
    "        self.num_batches = self.num_samples // self.batch_size\n",
    "        \n",
    "        # test paths and prediction matrix\n",
    "        self.X_test_ids, self.predictions = self.prepare_test_data_and_prediction()\n",
    "        \n",
    "        # variables to make batch generating easier\n",
    "        self.batch_idx = cycle(range(self.num_batches))\n",
    "        self.batch_num = next(self.batch_idx)\n",
    "        \n",
    "        self.num_val_samples = self.X_val.shape[0]\n",
    "        self.num_val_batches = self.y_val.shape[0] // self.batch_size\n",
    "        self.val_batch_idx = cycle(range(self.num_val_batches))\n",
    "        self.val_batch_num = next(self.val_batch_idx)\n",
    "        \n",
    "        self.num_test_samples = self.X_test_ids.shape[0]\n",
    "        self.num_test_batches = self.num_test_samples // self.batch_size\n",
    "        self.test_batch_idx = cycle(range(self.num_test_batches))\n",
    "        self.test_batch_num = next(self.test_batch_idx)\n",
    "    \n",
    "        # for testing iterator in test_mode\n",
    "        self.train_data_seen = pd.DataFrame(data={'seen': 0}, index=self.y_train.index)\n",
    "        \n",
    "        # test the generator\n",
    "        if test:\n",
    "            self._test_batch_generator()\n",
    "    def rescaling(self,x):\n",
    "        '''realy needs to be reworked!!!'''\n",
    "        return x/255#-244.709)/28.2702\n",
    "    \n",
    "    def binerizer(self,y):\n",
    "        '''realy needs to be reworked!!!'''\n",
    "        Y = []\n",
    "        y = np.int16(y/200)\n",
    "        for train in y:\n",
    "            Y.append(to_categorical(train,num_classes=2))\n",
    "    \n",
    "        return np.asarray(Y)\n",
    "    \n",
    "    def reconstruct(self,y):\n",
    "        y_back = []\n",
    "        for sample in y:\n",
    "            y_back.append(sample.argmax(1))\n",
    "\n",
    "        y_back = np.asarray(y_back)\n",
    "        y_back = y_back.reshape(y.shape[0], self.height, self.width) \n",
    "        \n",
    "        return y_back \n",
    "        \n",
    "    def prepare_test_data_and_prediction(self):\n",
    "        \"\"\"\n",
    "        Returns paths to test data indexed by subject_id \n",
    "        and preallocates prediction dataframe.\n",
    "        \"\"\"\n",
    "        \n",
    "        predpath = os.path.join(self.datapath, 'submission_format.csv')\n",
    "        predictions = pd.read_csv(predpath, index_col='filename')\n",
    "        test_idx = predictions.index\n",
    "        subjpath = os.path.join(self.datapath, self.dataset_type)\n",
    "        #subject_ids = pd.read_csv(subjpath, index_col=0)\n",
    "        subject_ids = pd.DataFrame(data=subjpath, columns=['filepath'], index=test_idx)\n",
    "        for row in subject_ids.itertuples():\n",
    "            subject_ids.loc[row.Index] = os.path.join(row.filepath, str(row.Index)) \n",
    "        \n",
    "        return test_idx, predictions\n",
    "  \n",
    "    \n",
    "    def split_training_into_validation(self):\n",
    "        \"\"\"\n",
    "        Uses the multilabel_train_test_split function \n",
    "        to load dataframe with filenames for train and validation.\n",
    "        \"\"\"\n",
    "\n",
    "        datapath = self.datapath\n",
    "        dataset_type = self.dataset_type\n",
    "        val_size = self.val_size\n",
    "        \n",
    "        # load training labels\n",
    "        labelpath = os.path.join(datapath, 'infos.csv')\n",
    "        labels = pd.read_csv(labelpath,index_col = 'nr')#index_col='filename'       \n",
    "        \n",
    "        # split\n",
    "        X_train, X_val, y_train, y_val = multilabel_train_test_split(X=labels['scatter'],Y=labels['real'],\n",
    "                                                                     size=val_size, seed=42)\n",
    "        \n",
    "        return X_train, X_val, y_train, y_val\n",
    "\n",
    "    def batches(self):\n",
    "        \"\"\"This method yields the next batch of images for training.\"\"\"\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "        num_train = self.y_train.shape[0]\n",
    "        \n",
    "        while 1:\n",
    "            # get videos\n",
    "            start = self.batch_size*self.batch_num\n",
    "            stop = self.batch_size*(self.batch_num + 1)\n",
    "            \n",
    "            # print batch rangesrain if testing\n",
    "            if self.test:\n",
    "                print(\"batch {0}:\\t{1} --> {2}\".format(self.batch_num,start, stop-1))\n",
    "            \n",
    "            failed = []\n",
    "            x_paths = self.X_train.iloc[start:stop]\n",
    "            x = self._get_image_batch(x_paths)\n",
    "            \n",
    "            # get labels\n",
    "            y_paths = self.y_train.iloc[start:stop]\n",
    "            y = self._get_image_batch(y_paths)\n",
    "            \n",
    "            # check match for labels and videos\n",
    "            assert (x_paths.index==y_paths.index).all()\n",
    "            assert x.shape[0] == y.shape[0]\n",
    "\n",
    "            # report failures if verbose\n",
    "            if len(failed) != 0 and verbose==True:\n",
    "                print(\"\\t\\t\\t*** ERROR FETCHING BATCH {0}/{1} ***\".format(self.batch_num,self.num_batches))\n",
    "                print(\"Dropped {0} videos:\".format(len(failed)))\n",
    "                for failure in failed:\n",
    "                    print(\"\\t{0}\\n\\n\".format(failure))\n",
    "\n",
    "            # increment batch number\n",
    "            self.batch_num = next(self.batch_idx)\n",
    "            \n",
    "            # update dataframe of seen training indices for testing\n",
    "            self.train_data_seen.loc[y_paths.index.values] = 1\n",
    "            \n",
    "            yield (self.rescaling(x), self.binerizer(y))\n",
    "            \n",
    "    def val_batches(self):\n",
    "        \"\"\"This method yields the next batch of images for validation.\"\"\"\n",
    "        \n",
    "        batch_size = self.batch_size\n",
    "        num_train = self.y_val.shape[0]\n",
    "        failed = []\n",
    "        \n",
    "        \n",
    "        while 1:\n",
    "            # get videos\n",
    "            start = self.batch_size*self.val_batch_num\n",
    "            stop = self.batch_size*(self.val_batch_num + 1)\n",
    "            \n",
    "            x_paths = self.X_val.iloc[start:stop]\n",
    "            x = self._get_image_batch(x_paths)\n",
    "            \n",
    "            # get labels\n",
    "            y_paths = self.y_val.iloc[start:stop]\n",
    "            y = self._get_image_batch(y_paths)\n",
    "\n",
    "            # check match for labels and videos\n",
    "            assert (x_paths.index==y_paths.index).all()\n",
    "            assert x.shape[0] == y.shape[0]\n",
    "\n",
    "            # report failures if verbose\n",
    "            if len(failed) != 0 and verbose==True:\n",
    "                print(\"\\t\\t\\t*** ERROR FETCHING BATCH {0}/{1} ***\".format(self.batch_num,self.num_batches))\n",
    "                print(\"Dropped {0} videos:\".format(len(failed)))\n",
    "                for failure in failed:\n",
    "                    print(\"\\t{0}\\n\\n\".format(failure))\n",
    "\n",
    "\n",
    "            # increment batch number\n",
    "            self.val_batch_num = next(self.val_batch_idx)\n",
    "            \n",
    "            yield (self.rescaling(x), self.binerizer(y))\n",
    "\n",
    "    def test_batches(self):\n",
    "        \"\"\"This method yields the next batch of images for testing.\"\"\"\n",
    "        \n",
    "        batch_size = self.batch_size\n",
    "        num_test = self.num_test_samples\n",
    "        \n",
    "        test_dir = os.path.join(self.datapath, self.dataset_type)\n",
    "        \n",
    "        \n",
    "        while 1:\n",
    "            # get videos\n",
    "            start = self.batch_size*self.test_batch_num\n",
    "            stop = self.batch_size*(self.test_batch_num + 1)\n",
    "            \n",
    "            x_ids = self.X_test_ids[start:stop]\n",
    "            x_paths = pd.DataFrame(data=[os.path.join(test_dir, \"{0}\".format(filename)) for filename in x_ids], \n",
    "                                   columns=['filepath'],\n",
    "                                   index=x_ids)\n",
    "            #print(x_paths)\n",
    "            x = self._get_image_batch(x_paths)\n",
    "            \n",
    "            self.test_batch_ids = x_ids.values\n",
    "\n",
    "            # increment batch number\n",
    "            self.test_batch_num = next(self.test_batch_idx)\n",
    "            \n",
    "            yield self.rescaling(x)\n",
    "\n",
    "    def _get_image_batch(self, x_paths, as_grey=True):\n",
    "        \"\"\"\n",
    "        Returns ndarray of shape (batch_size, width, height, channels).\n",
    "        If as_grey, then channels dimension is squeezed out.\n",
    "        \"\"\"\n",
    "\n",
    "        images = []\n",
    "        \n",
    "        for filepath in x_paths:\n",
    "            images.append(misc.imread(filepath))\n",
    "        \n",
    "        if as_grey:\n",
    "            images = np.asarray(images)[:,:,:,0].reshape(self.batch_size,self.width, self.height,1)\n",
    "        else:\n",
    "            images = np.asarray(images)\n",
    "        return images\n",
    "\n",
    "    def _test_batch_generator(self):\n",
    "        \n",
    "        print('Testing train batch generation...')\n",
    "        \n",
    "        for i in range(self.num_batches):\n",
    "            if self.batch_num % 10 == 0:\n",
    "                print(\"\\t\\t\\t*** ERROR FETCHING BATCH {0}/{1} ***\".format(self.batch_num,self.num_batches))\n",
    "                \n",
    "            batch = self.batches()\n",
    "            x,y = next(batch)\n",
    "        \n",
    "            # same batches for videos and labels\n",
    "            assert x.shape[0] == y.shape[0]\n",
    "            \n",
    "            # square videos\n",
    "            assert x.shape[2] == x.shape[3]\n",
    "            \n",
    "            # black and white\n",
    "            assert x.shape[4] == 1\n",
    "            \n",
    "        \n",
    "        # assert we've seen all data up to remainder of a batch\n",
    "        assert (self.y_train.shape[0] - self.train_data_seen.sum().values[0]) < self.batch_size\n",
    "        \n",
    "        # check that batch_num is reset\n",
    "        assert self.batch_num == 0\n",
    "        \n",
    "        # turn off test mode\n",
    "        if self.test == True:\n",
    "            self.test = False\n",
    "        \n",
    "        print('Test passed.')\n",
    "        \n",
    "    def update_predictions(self, results):\n",
    "        self.predictions.loc[self.test_batch_ids] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
